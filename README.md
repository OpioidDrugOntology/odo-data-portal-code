# ODO Data Portal Code  

This repository provides the reproducible **code and workflows** for the **Opioid Drug Ontology (ODO) Data Portal**.  
It includes scripts, pipelines, and environment specifications to ensure analyses can be run locally by any user.

- **Release v1.0.0** will correspond to the ODO Data Descriptor paper (DOI will be added automatically once the GitHub Release is archived in Zenodo).  
- Future releases will correspond to additional ODO-related publications.  
- All code is designed to run locally with Python 3.x (via conda, see `environment.yml`).  

---

## ğŸš€ Quickstart  

Run the demo pipeline and descriptor generation locally:  

```bash
# 1. Set up environment (once)
conda env create -f environment.yml
conda activate odo-chem

# 2. Run pipeline (input â†’ standardized output)
python pipelines/AutoMID_pipeline_S1-S5.py \
  --in data/example_input.csv \
  --out data/example_output.csv \
  --smiles-col smiles \
  --id-col odo_id

# 3. Run descriptor generation (output â†’ InChI, InChIKey, MW, MF)
python pipelines/simple_descriptors.py \
  --in data/example_output.csv \
  --out data/example_descriptors.csv


---

## âš™ï¸ Requirements

- [Conda (Miniconda/Anaconda)](https://docs.conda.io/en/latest/miniconda.html)  
- Python **3.8+** (tested with Python 3.10/3.11)  
- [RDKit](https://www.rdkit.org/) and [pandas](https://pandas.pydata.org/) (installed via the provided environment file)  
- [PyYAML](https://pyyaml.org/)  

> Inside the conda environment, `python` will already be Python 3, so either `python` or `python3` works.

---

## ğŸ“¦ Installation

Clone the repo and create the environment:

```bash
git clone https://github.com/OpioidDrugOntology/odo-data-portal-code.git
cd odo-data-portal-code

conda env create -f environment.yml
conda activate odo-chem


---


## ğŸ“‚ Repository Structure

```<pre>
odo-data-portal-code/
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ AutoMID_pipeline_S1-S5.py   # âš™ï¸ main standardization pipeline
â”‚   â””â”€â”€ simple_descriptors.py       # âš›ï¸ descriptor generation script
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ example_input.csv           # ğŸ“„ demo input (3 compounds)
â”‚   â”œâ”€â”€ example_output.csv          # ğŸ“Š pipeline output (S0â†’S5 results)
â”‚   â””â”€â”€ example_descriptors.csv     # âš›ï¸ descriptor output (InChI, InChIKey, MW, MF)
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                 # âš™ï¸ default settings for pipeline
â”œâ”€â”€ environment.yml                 # ğŸ› ï¸ conda environment setup
â”œâ”€â”€ LICENSE                         # ğŸ“œ license file
â””â”€â”€ README.md                       # ğŸ“– project documentation
```


---


## ğŸ“Š Demo Data
Workflow:
ğŸ“„ example_input.csv â†’ âš™ï¸ Pipeline (S0â†’S5) â†’ ğŸ“Š example_output.csv â†’ âš›ï¸ Descriptor Generation â†’ ğŸ“ˆ example_descriptors.csv

data/example_input.csv â€” 3 compounds (neutral, HCl salt, [3H]-labeled)

data/example_output.csv â€” standardized results after S0â†’S5 pipeline

data/example_descriptors.csv â€” computed molecular descriptors (InChI, InChIKey, MW, MF)


ğŸ”‘ Highlights
---
âš™ï¸ Pipeline (S0â†’S5)

S2: Removes counter-ions (e.g., .Cl) and retains the largest organic fragment

S5: Clears isotope labels (e.g., [3H]) for clean standardization

âš› Descriptor Generation

Converts each standardized SMILES into InChI and InChIKey

Computes molecular properties: Molecular Weight (MW) and Molecular Formula (MF)


âš™ Re-run Pipeline Locally

conda activate odo-chem
python pipelines/AutoMID_pipeline_S1-S5.py \
  --in data/example_input.csv \
  --out data/example_output.csv \
  --smiles-col smiles \
  --id-col odo_id

After running the S1â€“S5 pipeline, you can compute simple molecular descriptors:


âš› Run Descriptor Generation

conda activate odo-chem
python pipelines/simple_descriptors.py \
  --in data/example_output.csv \
  --out data/example_descriptors.csv

---


## ğŸ“‘ Notes

- **Document metadata** (PMID, DOI, patent IDs) were retrieved directly from the [ChEMBL API](https://www.ebi.ac.uk/chembl/) (release 34).  

- **Because these are simple API lookups, no custom code is required here â€” just cite the ChEMBL API as the source.

- **All non-trivial processing code (pipeline, descriptors) is deposited in this repository for transparency.
